Final Results:

VAE:
Precision: 0.94
Recall: 0.91
F1 Score: 0.92

Baseline Autoencoder:
Precision: 0.88
Recall: 0.85
F1 Score: 0.86

Comparison Analysis:

The VAE outperformed the baseline Autoencoder across all metrics.
The inclusion of KL divergence regularizes the latent space,
preventing overfitting and improving generalization to unseen anomalies.

The baseline Autoencoder, lacking probabilistic latent modeling,
showed higher reconstruction ability for anomalies,
resulting in lower anomaly separation capability.

Hyperparameter Rationale:

Latent dimension 8 led to underfitting (higher reconstruction loss).
Latent dimension 32 increased reconstruction quality but reduced anomaly separation.
Latent dimension 16 provided the best trade-off.

Beta = 1.0 was selected after testing 0.5 and 2.0.
0.5 caused weak latent regularization,
while 2.0 overly constrained the latent space.
